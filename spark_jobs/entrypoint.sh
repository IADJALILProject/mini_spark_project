#!/bin/bash

echo "ğŸ”„ Attente de la prÃ©sence du fichier /dbfs/users.csv..."

for i in {1..60}; do
  if [ -f "/dbfs/users.csv" ]; then
    echo "âœ… Fichier trouvÃ© !"
    break
  fi
  echo "â³ Attente... ($i/60)"
  sleep 1
done

if [ ! -f "/dbfs/users.csv" ]; then
  echo "âŒ ERREUR : Le fichier /dbfs/users.csv est introuvable aprÃ¨s 60s."
  exit 1
fi

echo "ğŸ“Š PrÃ©-vÃ©rification du schÃ©ma Spark..."

cat <<EOF > /tmp/check_schema.py
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("SchemaCheck").getOrCreate()
df = spark.read.option("header", True).option("inferSchema", True).csv("/dbfs/users.csv")
print("âœ… Colonnes dÃ©tectÃ©es :", df.columns)
df.printSchema()
spark.stop()
EOF

spark-submit --master "$SPARK_MASTER" --deploy-mode client /tmp/check_schema.py
echo "âœ… SchÃ©ma vÃ©rifiÃ© !"
echo "ğŸ”„ PrÃ©paration de l'environnement Spark..."

echo "ğŸš€ Lancement du traitement principal Spark"
spark-submit --master "$SPARK_MASTER" --deploy-mode client /opt/spark_jobs/process_users.py
echo "âœ… Traitement terminÃ© !"